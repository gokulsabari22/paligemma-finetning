{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6ff7dc4-e71e-4d8e-8ecf-fe3c225f2467",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "143d1390-45ed-4fcb-9239-f8b5c59210ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import PaliGemmaForConditionalGeneration, PaliGemmaProcessor\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import (AdamW, AutoProcessor, get_scheduler)\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoProcessor, BitsAndBytesConfig\n",
    "from peft import LoraConfig\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416f847-6da7-40d7-aceb-a323725f5ecb",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca3bda88-c2f7-406f-84b6-ab6cdfbd8a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"gokulsabari/brain_scan\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5eb4e73-0469-4d05-9157-f85ec0aa87a5",
   "metadata": {},
   "source": [
    "The dataset consists of image and caption. The captions are the observations from the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ccf1cd1-a942-455e-9509-6b4edc814cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'id', 'caption', 'ground_truth'],\n",
       "        num_rows: 136960\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'id', 'caption', 'ground_truth'],\n",
       "        num_rows: 24170\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa00356-23df-4d08-b9c6-fde87402a75d",
   "metadata": {},
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec47dc-9075-4aaf-a23b-a12ccc3bf0b0",
   "metadata": {},
   "source": [
    "#### The model has been trained using RTX 4090 24GB VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd0a1b1-c061-49a9-ab2c-33ff5f487870",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5fed9c6-271f-4b4f-bdef-da95ea74a8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75179834-b918-4646-a94b-04fd3fc37e54",
   "metadata": {},
   "source": [
    "### Base Model - Paligemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098b48c3-1397-4307-a44f-3f45e55d53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google/paligemma-3b-pt-224\"\n",
    "processor = PaliGemmaProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc42aef-3e35-4b12-aa7c-e9de54bd4390",
   "metadata": {},
   "source": [
    "### Dataset Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be893f-afd4-43f7-9322-9098630b3134",
   "metadata": {},
   "source": [
    "#### Defining collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4a20fc9-c9fb-4ef0-b33e-3f301ef7cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_token = processor.tokenizer.convert_tokens_to_ids(\"<image>\")\n",
    "question = \"\"\"Analyze the provided medical brain imaging scan. \n",
    "Describe the type of scan, key anatomical structures visible, and any abnormal findings.\n",
    "Focus on: Identifying the imaging modality (e.g., CT, MRI). Describing the view and orientation of the scan\n",
    "Noting any visible anatomical structures. Identifying and describing any abnormalities or areas of concern \n",
    "along with their approximate area as a % of the total image area\n",
    "Specifying the location of abnormalities using anatomical terms. Suggesting possible clinical implications of the findings\n",
    "Provide a concise yet comprehensive analysis in a professional medical tone.\"\"\"\n",
    "\n",
    "def collate_fn(examples):\n",
    "  texts = [question for _ in examples]\n",
    "  labels= [example['caption'] for example in examples]\n",
    "  images = [example[\"image\"].convert(\"RGB\") for example in examples]\n",
    "  tokens = processor(text=texts, images=images, suffix=labels,\n",
    "                    return_tensors=\"pt\", padding=\"longest\",\n",
    "                    tokenize_newline_separately=False)\n",
    "\n",
    "  tokens = tokens.to(torch.bfloat16).to(device)\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b241d17-07e0-4473-92e8-0ee784f00e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gangaai/.local/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:137: FutureWarning: The `vocab_size` attribute is deprecated and will be removed in v4.44, Please use `text_config.vocab_size` instead.\n",
      "  warnings.warn(\n",
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62bc31eed1984a9f85bbf2b1fa70b15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PaliGemmaForConditionalGeneration(\n",
       "  (vision_tower): SiglipVisionModel(\n",
       "    (vision_model): SiglipVisionTransformer(\n",
       "      (embeddings): SiglipVisionEmbeddings(\n",
       "        (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n",
       "        (position_embedding): Embedding(256, 1152)\n",
       "      )\n",
       "      (encoder): SiglipEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-26): 27 x SiglipEncoderLayer(\n",
       "            (self_attn): SiglipSdpaAttention(\n",
       "              (k_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "              (v_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "              (q_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "              (out_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): SiglipMLP(\n",
       "              (activation_fn): PytorchGELUTanh()\n",
       "              (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "              (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (multi_modal_projector): PaliGemmaMultiModalProjector(\n",
       "    (linear): Linear(in_features=1152, out_features=2048, bias=True)\n",
       "  )\n",
       "  (language_model): GemmaForCausalLM(\n",
       "    (model): GemmaModel(\n",
       "      (embed_tokens): Embedding(257216, 2048, padding_idx=0)\n",
       "      (layers): ModuleList(\n",
       "        (0-17): 18 x GemmaDecoderLayer(\n",
       "          (self_attn): GemmaSdpaAttention(\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "            (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (rotary_emb): GemmaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): GemmaMLP(\n",
       "            (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "            (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "            (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
       "            (act_fn): PytorchGELUTanh()\n",
       "          )\n",
       "          (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "          (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "        )\n",
       "      )\n",
       "      (norm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=2048, out_features=257216, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.bfloat16).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c361766-a9d7-46e6-9ca4-acff3735c3a4",
   "metadata": {},
   "source": [
    "### We have freezed the vision encoder and text decoder and unfreezed the projector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef584549-052d-4d87-b324-09536233735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.vision_tower.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.language_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45a5bf82-720a-4cbf-9258-83b322548135",
   "metadata": {},
   "source": [
    "Below code can be used to fine-tune the base model using QLoRA method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1de2c887-e954-404a-89f1-0b4de7d11788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lora_config = LoraConfig(\n",
    "#     r=8,\n",
    "#     lora_alpha=8,\n",
    "#     lora_dropout=0.1,\n",
    "#     target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "#     init_lora_weights=\"gaussian\"\n",
    "# )\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_8bit=True,            \n",
    "# )\n",
    "# model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "#     model_id,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     quantization_config=bnb_config\n",
    "# )\n",
    "# model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n",
    "# model.add_adapter(lora_config)\n",
    "# model.enable_adapters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1036eb-1660-4db1-af18-f6784f844f94",
   "metadata": {},
   "source": [
    "### Defining the training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e498d676-5824-4481-8626-c79acaa8c5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    num_train_epochs=100,\n",
    "    remove_unused_columns=False,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=2,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=1e-6,\n",
    "    adam_beta2=0.999,\n",
    "    logging_steps=100,\n",
    "    optim=\"adamw_hf\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_steps=1000,\n",
    "    push_to_hub=True,\n",
    "    save_total_limit=1,\n",
    "    output_dir=\"paligemma-adapter\",\n",
    "    bf16=True,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    dataloader_pin_memory=False,\n",
    "    evaluation_strategy=\"epoch\",  \n",
    "    eval_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    # Early stopping parameters\n",
    "    early_stopping_patience=3,\n",
    "    early_stopping_threshold=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f3603e9-da62-48f9-8472-e6db912e814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        train_dataset=dataset['train'],\n",
    "        eval_dataset=dataset['test'],\n",
    "        data_collator=collate_fn,\n",
    "        args=args\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55a95526-0f6e-4f7d-82a1-966c5ef031be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gangaai/.local/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/gangaai/.local/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:137: FutureWarning: The `vocab_size` attribute is deprecated and will be removed in v4.44, Please use `text_config.vocab_size` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='85600' max='85600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [85600/85600 28:05:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.028800</td>\n",
       "      <td>1.035887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.014900</td>\n",
       "      <td>1.013301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.019700</td>\n",
       "      <td>1.009638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.007300</td>\n",
       "      <td>1.008637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.005400</td>\n",
       "      <td>1.008433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.011200</td>\n",
       "      <td>1.008285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.017300</td>\n",
       "      <td>1.008306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.017500</td>\n",
       "      <td>1.008329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.018100</td>\n",
       "      <td>1.008236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.002200</td>\n",
       "      <td>1.008252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gangaai/.local/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:137: FutureWarning: The `vocab_size` attribute is deprecated and will be removed in v4.44, Please use `text_config.vocab_size` instead.\n",
      "  warnings.warn(\n",
      "/home/gangaai/.local/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:137: FutureWarning: The `vocab_size` attribute is deprecated and will be removed in v4.44, Please use `text_config.vocab_size` instead.\n",
      "  warnings.warn(\n",
      "/home/gangaai/.local/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:137: FutureWarning: The `vocab_size` attribute is deprecated and will be removed in v4.44, Please use `text_config.vocab_size` instead.\n",
      "  warnings.warn(\n",
      "/home/gangaai/.local/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:137: FutureWarning: The `vocab_size` attribute is deprecated and will be removed in v4.44, Please use `text_config.vocab_size` instead.\n",
      "  warnings.warn(\n",
      "HTTP Error 500 thrown while requesting PUT https://hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com/repos/76/2f/762fd2ac66a397735c383fc1e40352f14e1e313215b0dd85eb681b45342780e8/2d6c497917bc06d805d06c9dc46aed6fbaa2af04295afb867942daa6b08afdd4?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20240903%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240903T221755Z&X-Amz-Expires=86400&X-Amz-Signature=b314115850e3e51d74dc6e8c894ef39c7dedd5bc04dfb5721e40eca0566fe894&X-Amz-SignedHeaders=host&partNumber=252&uploadId=6XL1ib9I5PNZVyybqPhnBcidLxscGm2V9hrWxpagmnE3XD1Liunpyn__mqlRDMSumwtU9o.9a2hygQ7spfx9QXcBEF2DXtOA0y_q.DkUC6.srSZ8qkuKq0Yjm7ffZwsP&x-id=UploadPart\n",
      "Retrying in 1s [Retry 1/5].\n",
      "/home/gangaai/.local/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:137: FutureWarning: The `vocab_size` attribute is deprecated and will be removed in v4.44, Please use `text_config.vocab_size` instead.\n",
      "  warnings.warn(\n",
      "/home/gangaai/.local/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:137: FutureWarning: The `vocab_size` attribute is deprecated and will be removed in v4.44, Please use `text_config.vocab_size` instead.\n",
      "  warnings.warn(\n",
      "/home/gangaai/.local/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:137: FutureWarning: The `vocab_size` attribute is deprecated and will be removed in v4.44, Please use `text_config.vocab_size` instead.\n",
      "  warnings.warn(\n",
      "/home/gangaai/.local/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:137: FutureWarning: The `vocab_size` attribute is deprecated and will be removed in v4.44, Please use `text_config.vocab_size` instead.\n",
      "  warnings.warn(\n",
      "/home/gangaai/.local/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:137: FutureWarning: The `vocab_size` attribute is deprecated and will be removed in v4.44, Please use `text_config.vocab_size` instead.\n",
      "  warnings.warn(\n",
      "/home/gangaai/.local/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:137: FutureWarning: The `vocab_size` attribute is deprecated and will be removed in v4.44, Please use `text_config.vocab_size` instead.\n",
      "  warnings.warn(\n",
      "There were missing keys in the checkpoint model loaded: ['language_model.lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=85600, training_loss=1.02722936059827, metrics={'train_runtime': 101156.4145, 'train_samples_per_second': 13.539, 'train_steps_per_second': 0.846, 'total_flos': 9.987645287412793e+18, 'train_loss': 1.02722936059827, 'epoch': 10.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cc24ac6-2a78-453b-9d43-1216ddd0eb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gangaai/.local/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:137: FutureWarning: The `vocab_size` attribute is deprecated and will be removed in v4.44, Please use `text_config.vocab_size` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/gokulsabari/paligemma-adapter/commit/0c555ec77eda429e593aca62dfd188954f6270d1', commit_message='End of training', commit_description='', oid='0c555ec77eda429e593aca62dfd188954f6270d1', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e02fed-4c0c-42cf-85f3-7fbc32f95d86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
