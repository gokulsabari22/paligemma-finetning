{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e74ac9c3-b737-4e3e-b63b-37682942d816",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "543264cf-4920-4bb9-9a16-4c9326d049d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoProcessor\n",
    "from typing import Dict, List, Any\n",
    "import random\n",
    "import lightning as L\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import re\n",
    "from nltk import edit_distance\n",
    "import numpy as np\n",
    "from transformers import PaliGemmaForConditionalGeneration\n",
    "from transformers import BitsAndBytesConfig\n",
    "from peft import get_peft_model, LoraConfig\n",
    "import accelerate\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor  \n",
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7948cc9-2a2e-4beb-b790-26e072332bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_ID = \"google/paligemma-3b-pt-224\"\n",
    "FINETUNED_MODEL_ID = \"gokulsabari/paligemma-brain-xray\"\n",
    "MAX_LENGTH = 512\n",
    "WANDB_PROJECT = \"paligemma\"\n",
    "WANDB_NAME = \"brain-xray-demo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8a79ae-28b4-46fd-8ccf-2583baa3c3cc",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "973e1e7a-e4d4-4ab3-b9f5-1bc05a25b177",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"gokulsabari/brain-xray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbce0968-e6a8-4ea8-8126-7d418dd6d79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'id', 'caption', 'ground_truth'],\n",
       "        num_rows: 161130\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'id', 'caption', 'ground_truth'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28c27a0-e761-46e6-b8ae-ef7fd45f9fc0",
   "metadata": {},
   "source": [
    "## Viewing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fe5fa06-f77f-475c-b4b8-90165bbaf864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=153x153>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset[\"train\"][0]\n",
    "image = example[\"image\"]\n",
    "width, height = image.size\n",
    "image = image.resize((int(0.3*width), int(0.3*height)))\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a1c2f8-a1bb-4e4f-8f12-825161e39c73",
   "metadata": {},
   "source": [
    "## Text preprocessing to load  the answer as json. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a08b7e5d-9d54-41f7-a365-812a0a846aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_json_string(json_str):\n",
    "    # Replace single quotes with double quotes for the outer structure\n",
    "    json_str = json_str.replace(\"'\", '\"')\n",
    "    \n",
    "    # Find the \"answer\" field and escape its internal double quotes\n",
    "    pattern = r'\"answer\"\\s*:\\s*\"(.*?)\"(?=\\s*\\})'\n",
    "    \n",
    "    def escape_quotes(match):\n",
    "        # Use regular string formatting instead of f-string\n",
    "        return '\"answer\": \"{}\"'.format(match.group(1).replace('\"', '\\\\\"'))\n",
    "    \n",
    "    fixed_json = re.sub(pattern, escape_quotes, json_str, flags=re.DOTALL)\n",
    "    \n",
    "    return fixed_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b2401e-9df9-417a-bc3c-72441867bbb7",
   "metadata": {},
   "source": [
    "## Ground Truth Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e87d7543-21f7-4964-8558-7697acb65ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gt_parse': {'question': 'Analyze the provided medical brain imaging scan. Describe the type of scan, key anatomical structures visible, and any abnormal findings. Focus on: Identifying the imaging modality (e.g., CT, MRI) Describing the view and orientation of the scan Noting any visible anatomical structures Identifying and describing any abnormalities or areas of concern Specifying the location of abnormalities using anatomical terms Suggesting possible clinical implications of the findings Provide a concise yet comprehensive analysis in a professional medical tone.',\n",
       "  'answer': 'The image is a non-contrasted computed tomography (CT) scan of the brain, showing the cerebral structures without any medical devices present. The region of interest, located centrally and in the middle of the image, exhibits an area of altered density, which is indicative of a brain hemorrhage. This area is distinct from the surrounding brain tissue, suggesting a possible hematoma or bleeding within the brain parenchyma. The location and characteristics of this abnormality may suggest a relationship with the surrounding brain tissue, potentially causing a mass effect or contributing to increased intracranial pressure.'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = example[\"ground_truth\"]\n",
    "ground_truth = ground_truth.replace('\\n', ' ').replace('  ', ' ')\n",
    "ground_truth = fix_json_string(ground_truth)\n",
    "ground_truth = json.loads(ground_truth)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa6c6690-a61a-4e51-8ed0-c58be3e46250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(ground_truth[\"gt_parse\"], dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b799e822-2c23-40f2-8279-ceadb1754de1",
   "metadata": {},
   "source": [
    "### Create a Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33f8b0ea-33d7-4eef-8d6c-89b23a4f560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                dataset_name: str,\n",
    "                split: str = \"train\",\n",
    "                sort_json_key: bool = True):\n",
    "        super().__init__()\n",
    "        self.split = split\n",
    "        self.sort_json_key = sort_json_key\n",
    "        self.dataset = load_dataset(path=dataset_name, split=self.split)\n",
    "        self.dataset_length = len(self.dataset)\n",
    "\n",
    "        self.gt_token_sequences = []\n",
    "        for sample in self.dataset:\n",
    "            ground_truth = sample[\"ground_truth\"]\n",
    "            ground_truth = ground_truth.replace('\\n', ' ')\n",
    "            ground_truth = fix_json_string(ground_truth)\n",
    "            ground_truth = json.loads(ground_truth)\n",
    "            if \"gt_parses\" in ground_truth:  \n",
    "                assert isinstance(ground_truth[\"gt_parses\"], list)\n",
    "                gt_jsons = ground_truth[\"gt_parses\"]\n",
    "            else:\n",
    "                assert \"gt_parse\" in ground_truth and isinstance(ground_truth[\"gt_parse\"], dict)\n",
    "                gt_jsons = [ground_truth[\"gt_parse\"]]\n",
    "\n",
    "            \n",
    "            self.gt_token_sequences.append(\n",
    "                [\n",
    "                    self.json2token(\n",
    "                        gt_json,\n",
    "                        sort_json_key=self.sort_json_key,\n",
    "                    )\n",
    "                    for gt_json in gt_jsons  # load json from list of json\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def json2token(self, obj: Any, sort_json_key: bool = True):\n",
    "        \"\"\"\n",
    "        Convert an ordered JSON object into a token sequence\n",
    "        \"\"\"\n",
    "        if type(obj) == dict:\n",
    "            if len(obj) == 1 and \"text_sequence\" in obj:\n",
    "                return obj[\"text_sequence\"]\n",
    "            else:\n",
    "                output = \"\"\n",
    "                if sort_json_key:\n",
    "                    keys = sorted(obj.keys(), reverse=True)\n",
    "                else:\n",
    "                    keys = obj.keys()\n",
    "                for k in keys:\n",
    "                    output += (\n",
    "                        fr\"<s_{k}>\"\n",
    "                        + self.json2token(obj[k], sort_json_key)\n",
    "                        + fr\"</s_{k}>\"\n",
    "                    )\n",
    "                return output\n",
    "        elif type(obj) == list:\n",
    "            return r\"<sep/>\".join(\n",
    "                [self.json2token(item, sort_json_key) for item in obj]\n",
    "            )\n",
    "        else:\n",
    "            obj = str(obj)\n",
    "            return obj\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.dataset_length\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict:\n",
    "        \"\"\"\n",
    "        Returns one item of the dataset.\n",
    "\n",
    "        Returns:\n",
    "            image : the original Receipt image\n",
    "            target_sequence : tokenized ground truth sequence\n",
    "        \"\"\"\n",
    "        sample = self.dataset[idx]\n",
    "\n",
    "        # inputs\n",
    "        image = sample[\"image\"]\n",
    "        target_sequence = random.choice(self.gt_token_sequences[idx])  \n",
    "\n",
    "        return image, target_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1d7a203-6577-44da-9da0-a1c502a96bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(dataset_name=\"gokulsabari/brain-xray\", split=\"train\")\n",
    "test_dataset = CustomDataset(dataset_name=\"gokulsabari/brain-xray\", split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabdf85d-622f-4184-b2c0-917713d3a16a",
   "metadata": {},
   "source": [
    "### Create Collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0253f03f-a325-41c6-9d35-928d4384d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"Analyze the provided medical brain imaging scan. Describe the type of scan, key anatomical structures visible, and any abnormal findings. Focus on: Identifying the imaging modality (e.g., CT, MRI) Describing the view and orientation of the scan Noting any visible anatomical structures Identifying and describing any abnormalities or areas of concern Specifying the location of abnormalities using anatomical terms Suggesting possible clinical implications of the findings Provide a concise yet comprehensive analysis in a professional medical tone.\"\"\"\n",
    "\n",
    "pattern = r'(<s_answer>.*?</s_answer>)'\n",
    "\n",
    "\n",
    "def train_collate_fn(examples):\n",
    "    images = [example[0] for example in examples]\n",
    "    texts = [PROMPT for _ in range(len(images))]\n",
    "\n",
    "    labels = []      # The answer file contains <s_question>question</s_question><s_answer>answer</s_question>. \n",
    "                     # We only need <s_answer>answer</s_question>\n",
    "                     # Used regex to extract only the answer part\n",
    "\n",
    "    for example in examples:\n",
    "        label = example[1]\n",
    "        match = re.search(pattern, label, re.DOTALL)\n",
    "    \n",
    "        if match:\n",
    "            label = match.group(1)\n",
    "        labels.append(label)\n",
    "\n",
    "    \n",
    "    inputs = processor(text=texts, images=images, suffix=labels, return_tensors=\"pt\", padding=True,\n",
    "                     truncation=\"only_second\", max_length=MAX_LENGTH,\n",
    "                     tokenize_newline_separately=False)\n",
    "    \n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    token_type_ids = inputs[\"token_type_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    pixel_values = inputs[\"pixel_values\"]\n",
    "    labels = inputs[\"labels\"]\n",
    "    \n",
    "    \n",
    "  \n",
    "\n",
    "    return input_ids, token_type_ids, attention_mask, pixel_values, labels\n",
    "\n",
    "\n",
    "def eval_collate_fn(examples):\n",
    "  images = [example[0] for example in examples]\n",
    "  texts = [PROMPT for _ in range(len(images))]\n",
    "  answers = [example[1] for example in examples]\n",
    "\n",
    "  inputs = processor(text=texts, images=images, return_tensors=\"pt\", padding=True, tokenize_newline_separately=False)\n",
    "\n",
    "  input_ids = inputs[\"input_ids\"]\n",
    "  attention_mask = inputs[\"attention_mask\"]\n",
    "  pixel_values = inputs[\"pixel_values\"]\n",
    "\n",
    "  return input_ids, attention_mask, pixel_values, answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134f1298-3b1d-4de2-acc2-c20c204d767f",
   "metadata": {},
   "source": [
    "## Load the processor\n",
    "In Vision Language Models (VLMs), the processor plays a crucial role in preparing and transforming both image and text inputs into a format that the model can understand and process. It typically handles tasks such as resizing and normalizing images, tokenizing text, and combining these modalities into a single input representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23d0205c-beee-44d7-a01c-dcd6fc3b5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(REPO_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7c88ad5-b8a2-4509-bfe6-265c7e0001b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, collate_fn=train_collate_fn, batch_size=2, shuffle=True)\n",
    "input_ids, token_type_ids, attention_mask, pixel_values, labels = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cefccee4-720e-4684-8241-c0d6ec94c273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><bos>Analyze the provided medical brain imaging scan. Describe the type of scan, key anatomical structures visible, and any abnormal findings. Focus on: Identifying the imaging modality (e.g., CT, MRI) Describing the view and orientation of the scan Noting any visible anatomical structures Identifying and describing any abnormalities or areas of concern Specifying the location of abnormalities using anatomical terms Suggesting possible clinical implications of the findings Provide a concise yet comprehensive analysis in a professional medical tone.\\n<s_answer>The image is a non-contrasted computed tomography (CT) scan of the brain, showing the cranial cavity with brain structures. The region of interest, located centrally and in the upper-middle area of the brain, occupies approximately 0.9% of the area and appears to have a different density compared to the surrounding brain tissue, which may indicate an abnormality such as a hemorrhage. This region\"s unusual appearance, potentially representing a subdural hemorrhage, is situated near critical brain structures, which could suggest a relationship where the hemorrhage may exert pressure on or cause displacement of these structures.</s_answer><eos>',\n",
       " '<image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><bos>Analyze the provided medical brain imaging scan. Describe the type of scan, key anatomical structures visible, and any abnormal findings. Focus on: Identifying the imaging modality (e.g., CT, MRI) Describing the view and orientation of the scan Noting any visible anatomical structures Identifying and describing any abnormalities or areas of concern Specifying the location of abnormalities using anatomical terms Suggesting possible clinical implications of the findings Provide a concise yet comprehensive analysis in a professional medical tone.\\n<s_answer>The image is a non-contrast computed tomography (CT) scan of the brain, showing the cerebral structures without the use of contrast media. The region of interest, located centrally and in the upper-middle area of the brain, occupies approximately 0.4% of the image area and appears to have a different density compared to the surrounding brain tissue, which may indicate an abnormality such as a hemorrhage or a mass effect. This region\"s unusual appearance, potentially indicative of a disease process, is situated near critical brain structures, which could suggest a relationship where the disease within the region of interest could be exerting an effect on or be affected by the adjacent brain tissue.</s_answer><eos>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.batch_decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14633d67-b176-43ca-b6ce-c4ad47dfd0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(test_dataset, collate_fn=eval_collate_fn, batch_size=2, shuffle=False)\n",
    "input_ids, attention_mask, pixel_values, answers = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0351bd4f-43d6-4116-a1a7-c5f3a89eb5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><bos>Analyze the provided medical brain imaging scan. Describe the type of scan, key anatomical structures visible, and any abnormal findings. Focus on: Identifying the imaging modality (e.g., CT, MRI) Describing the view and orientation of the scan Noting any visible anatomical structures Identifying and describing any abnormalities or areas of concern Specifying the location of abnormalities using anatomical terms Suggesting possible clinical implications of the findings Provide a concise yet comprehensive analysis in a professional medical tone.\\n',\n",
       " '<image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><bos>Analyze the provided medical brain imaging scan. Describe the type of scan, key anatomical structures visible, and any abnormal findings. Focus on: Identifying the imaging modality (e.g., CT, MRI) Describing the view and orientation of the scan Noting any visible anatomical structures Identifying and describing any abnormalities or areas of concern Specifying the location of abnormalities using anatomical terms Suggesting possible clinical implications of the findings Provide a concise yet comprehensive analysis in a professional medical tone.\\n']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.batch_decode(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7533be5f-8236-480b-94fd-99c21648b1a6",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfaa7bf3-24b2-45e0-bd04-8ae2f3d6d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaliGemmaModelPLModule(L.LightningModule):\n",
    "    def __init__(self, config, processor, model):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.processor = processor\n",
    "        self.model = model\n",
    "\n",
    "        self.batch_size = config.get(\"batch_size\")\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask, pixel_values, labels = batch\n",
    "\n",
    "        outputs = self.model(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask,\n",
    "                                token_type_ids=token_type_ids,\n",
    "                                pixel_values=pixel_values,\n",
    "                                labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, dataset_idx=0):\n",
    "\n",
    "        input_ids, attention_mask, pixel_values, answers = batch\n",
    "\n",
    "        # autoregressively generate token IDs\n",
    "        generated_ids = self.model.generate(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                                       pixel_values=pixel_values, max_new_tokens=MAX_LENGTH)\n",
    "        # turn them back into text, chopping of the prompt\n",
    "        # important: we don't skip special tokens here, because we want to see them in the output\n",
    "        predictions = self.processor.batch_decode(generated_ids[:, input_ids.size(1):], skip_special_tokens=True)\n",
    "\n",
    "        scores = []\n",
    "        for pred, answer in zip(predictions, answers):\n",
    "            pred = re.sub(r\"(?:(?<=>) | (?=</s_))\", \"\", pred)\n",
    "            scores.append(edit_distance(pred, answer) / max(len(pred), len(answer)))\n",
    "\n",
    "            if self.config.get(\"verbose\", False) and len(scores) == 1:\n",
    "                print(f\"Prediction: {pred}\")\n",
    "                print(f\"    Answer: {answer}\")\n",
    "                print(f\" Normed ED: {scores[0]}\")\n",
    "\n",
    "        self.log(\"val_edit_distance\", np.mean(scores))\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.config['lr'])\n",
    "        \n",
    "        # Calculate total steps\n",
    "        total_steps = self.config['max_epochs'] * len(self.train_dataloader())\n",
    "        \n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=total_steps)\n",
    "    \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",  # or \"epoch\"\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(train_dataset, collate_fn=train_collate_fn, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(val_dataset, collate_fn=eval_collate_fn, batch_size=self.batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47cc9a3-138c-4bee-a521-1f1046a12217",
   "metadata": {},
   "source": [
    "## Training using PEFT (QLoRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c130004d-504b-44bf-a508-8eff35046390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['bnb_4bit_compute_type']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\paligemma\\configuration_paligemma.py:137: FutureWarning: The `vocab_size` attribute is deprecated and will be removed in v4.44, Please use `text_config.vocab_size` instead.\n",
      "  warnings.warn(\n",
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab47f2da81614f99a1db9e19bb1db00a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 11,298,816 || all params: 2,934,765,296 || trainable%: 0.3850\n"
     ]
    }
   ],
   "source": [
    "# Bits and Bytes config\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# LoRA config\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32,                # Higher rank and alpha can be set for complex tasks\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05\n",
    ")\n",
    "\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(REPO_ID, quantization_config=bnb_config, device_map={\"\":0}, torch_dtype=torch.bfloat16)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c667f36-514d-4290-a6c2-22dcd39b7f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"max_epochs\": 10,\n",
    "          # \"val_check_interval\": 0.2, # how many times we want to validate during an epoch\n",
    "          \"check_val_every_n_epoch\": 1,\n",
    "          \"gradient_clip_val\": 1.0,\n",
    "          \"accumulate_grad_batches\": 8,\n",
    "          \"lr\": 1e-4,\n",
    "          \"batch_size\": 2,\n",
    "          # \"seed\":2022,\n",
    "          \"num_nodes\": 1,\n",
    "          \"warmup_steps\": 50,\n",
    "          \"result_path\": \"./result\",\n",
    "          \"verbose\": True,\n",
    "}\n",
    "\n",
    "model_module = PaliGemmaModelPLModule(config, processor, model)\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c619a6cf-8776-4098-a0a3-6e39b1d00d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi()\n",
    "\n",
    "class PushToHubCallback(Callback):\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        print(f\"Pushing model to the hub, epoch {trainer.current_epoch}\")\n",
    "        pl_module.model.push_to_hub(FINETUNED_MODEL_ID,\n",
    "                                    commit_message=f\"Training in progress, epoch {trainer.current_epoch}\")\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        print(f\"Pushing model to the hub after training\")\n",
    "        pl_module.processor.push_to_hub(FINETUNED_MODEL_ID,\n",
    "                                    commit_message=f\"Training done\")\n",
    "        pl_module.model.push_to_hub(FINETUNED_MODEL_ID,\n",
    "                                    commit_message=f\"Training done\")\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_edit_distance\", patience=3, verbose=False, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d23629-6cf8-4dfc-871b-c60f5c23a685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                 | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model | PeftModelForCausalLM | 1.7 B  | train\n",
      "-------------------------------------------------------\n",
      "11.3 M    Trainable params\n",
      "1.7 B     Non-trainable params\n",
      "1.7 B     Total params\n",
      "6,948.584 Total estimated model params size (MB)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "        accelerator=\"gpu\",\n",
    "        devices=[0],\n",
    "        max_epochs=config.get(\"max_epochs\"),\n",
    "        accumulate_grad_batches=config.get(\"accumulate_grad_batches\"),\n",
    "        check_val_every_n_epoch=config.get(\"check_val_every_n_epoch\"),\n",
    "        gradient_clip_val=config.get(\"gradient_clip_val\"),\n",
    "        precision=\"16-mixed\",\n",
    "        limit_val_batches=5,\n",
    "        num_sanity_val_steps=0,\n",
    "        # logger=wandb_logger,\n",
    "        callbacks=[PushToHubCallback(), early_stop_callback, lr_monitor],\n",
    ")\n",
    "\n",
    "trainer.fit(model_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a530a57d-596f-457e-88c9-8a5ba8a1858e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
